{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGH6n6jKo1W7EpsrqSZD1U"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import random\n",
        "import json\n",
        "import csv\n",
        "\n",
        "# file_path = '/content/gdrive/MyDrive/chatgpt/archive'\n",
        "def create_dataset(file_path):\n",
        "  # read raw data\n",
        "  with open(file_path + '/je.test', 'r', encoding='utf-8') as f:\n",
        "      je_test = f.read()\n",
        "  with open(file_path + '/ko.test', 'r', encoding='utf-8') as f:\n",
        "      ko_test = f.read()\n",
        "\n",
        "  je_list = je_test.split('\\n')\n",
        "  ko_list = ko_test.split('\\n')\n",
        "\n",
        "  n = len(je_list)\n",
        "  test_num = 30\n",
        "\n",
        "  index_list = []\n",
        "  for i in range(n):\n",
        "    if '건 .' in je_list[i] or '언 .' in je_list[i] or '건 ?' in je_list[i] or '언 ?' in je_list[i] \\\n",
        "        or '잰 .' in je_list[i] or '헨 .' in je_list[i] or '헨 ?' in je_list[i] or '멘 .' in je_list[i] \\\n",
        "        or '젠 .' in je_list[i] or '안 .' in je_list[i] or '안 ?' in je_list[i] \\\n",
        "        or '단 .' in je_list[i] or '단 ?' in je_list[i] \\\n",
        "        or '수다 .' in je_list[i] or '수까 ?' in je_list[i]:\n",
        "      index_list.append(i) \n",
        "\n",
        "  n = len(index_list)\n",
        "  while n <= 311:\n",
        "    rand_num = random.randrange(1, n)\n",
        "    if rand_num not in index_list:\n",
        "      index_list.append(rand_num)\n",
        "      n+=1\n",
        "\n",
        "  random.shuffle(index_list)\n",
        "  train_index = index_list[:-test_num]\n",
        "  test_index = index_list[-test_num:]\n",
        "\n",
        "  train_data = [{\"dialect\": je_list[i], \"standard\": ko_list[i]} for i in train_index]\n",
        "  test_data = [{\"dialect\": je_list[i], \"standard\": ko_list[i]} for i in test_index]\n",
        "\n",
        "  with open('archive_train.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(train_data, f, indent='\\t', ensure_ascii=False)\n",
        "  with open('archive_test.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(test_data, f, indent='\\t', ensure_ascii=False)\n",
        "\n",
        "# file_path = '/content/gdrive/MyDrive/chatgpt/archive'\n",
        "def get_dataset(file_path):\n",
        "  with open(file_path + '/archive_train.json', 'r', encoding='utf-8') as f:\n",
        "      train_data = json.load(f)\n",
        "  with open(file_path + '/archive_test.json', 'r', encoding='utf-8') as f:\n",
        "      test_data = json.load(f)\n",
        "\n",
        "  return train_data, test_data\n",
        "\n",
        "def save_csv(test_json, file_name):\n",
        "  with open(file_name, 'w', newline= '') as output_file:\n",
        "    f = csv.writer(output_file)\n",
        "    f.writerow(['dialect', 'standard', 'response'])\n",
        "    for data in test_json:\n",
        "      f.writerow([data['dialect'], data['standard'], data['response']])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  openai.organization = \"org-dF7sWY08nuiUV36o3Gf9iNDb\"\n",
        "  openai.api_key = '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' #NY\n",
        "  #openai.api_key = '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' #DR\n",
        "  MODEL = \"gpt-3.5-turbo\"\n",
        "\n",
        "  train_data, test_data = get_dataset('/content/gdrive/MyDrive/chatgpt/archive')\n",
        "  test_num = len(test_data)\n",
        "\n",
        "  messages = []\n",
        "  test = []\n",
        "\n",
        "  for i in range(test_num):\n",
        "    if i==0:\n",
        "      message = '제주도 방언 문장을 표준어 문장으로 바꿔줘.\\n'\n",
        "    else:\n",
        "      del messages[-1]\n",
        "      del messages[-1]\n",
        "      message = '제주도 방언 문장을 표준어 문장으로 바꿔줘.\\n'\n",
        "    \n",
        "    test_dialect = test_data[i][\"dialect\"]\n",
        "    test_standard = test_data[i][\"standard\"]\n",
        "    message += f'''방언: {test_dialect}\\n'''\n",
        "    message += f'''표준어: '''\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": message})\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "    test_response = completion.choices[0].message.content\n",
        "\n",
        "    messages.append({\"role\": \"assistant\", \"content\": test_response})\n",
        "\n",
        "    test.append({\"dialect\": test_dialect, \"standard\": test_standard, \"response\": test_response})\n",
        "\n",
        "  save_csv(test, 'archive_result_vanilla.csv')"
      ],
      "metadata": {
        "id": "kxIXJfhXJet_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}